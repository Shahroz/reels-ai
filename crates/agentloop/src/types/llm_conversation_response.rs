//! Defines the structure for the LLM's response in a conversational context.
//!
//! This file contains the `LlmConversationResponse` struct, which is expected
//! to be returned by the LLM when processing conversational prompts using `llm_typed`.
//! It primarily holds the agent's textual response.
//! Adheres to the one-item-per-file and documentation guidelines.

// External crate imports for traits
use serde::{Deserialize, Serialize};
use schemars::JsonSchema;
use llm::few_shots_traits::FewShotsOutput; // InputOutputFewShot needed for example structure

/// Represents the structured response expected from the LLM for conversation tasks.
#[derive(Debug, Clone, Serialize, Deserialize, JsonSchema)]
pub struct LlmConversationResponse {
    /// The textual response generated by the agent.
    pub agent_response: String,
    // Future: Could add fields for tool calls, citations, etc.
}

// Implementation of FewShotsOutput to provide examples for the LLM prompt.
impl FewShotsOutput<LlmConversationResponse> for LlmConversationResponse {
    fn few_shots() -> Vec<LlmConversationResponse> {
        // Provide 1-2 simple examples of the expected output structure.
        std::vec![
            LlmConversationResponse {
                agent_response: String::from("Hello! How can I help you today?")
            },
            LlmConversationResponse {
                agent_response: String::from("The weather in London is currently sunny with a high of 22Â°C.")
            },
            // Example demonstrating slightly more complex response
            LlmConversationResponse {
                agent_response: String::from("To reset your password, please visit the login page and click the 'Forgot Password' link. You will receive an email with instructions.")
            }
        ]
    }
}

// No tests needed for a simple data structure with trait implementations.
